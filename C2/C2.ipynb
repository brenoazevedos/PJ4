{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\breno\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "c:\\Users\\breno\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\breno\\AppData\\Local\\Temp\\ipykernel_14352\\882793358.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  postagemAleatoria = postagemAleatoria.append(x[x.Classification == 1].sample(n = 5, random_state= 0, replace = True));\n",
      "C:\\Users\\breno\\AppData\\Local\\Temp\\ipykernel_14352\\882793358.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  postagemAleatoria = postagemAleatoria.append(x[x.Classification == 2].sample(n = 5, random_state= 0, replace = True));\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "def idf():\n",
    "  file = open(str(Path.home()) + \"\\Documents\\Python\\PJ4\\C2\\documentosNoDuplicate.txt\",\"r\", encoding=\"utf8\")\n",
    "  liststrings = file.readlines()\n",
    "  liststrings.remove('Nao lidaBem-vindo ao Facebook! Toque aqui para encontrar pessoas que voce conhece e adiciona-las aos amigos.\\n')\n",
    "  liststrings.remove('\\n')\n",
    "\n",
    "  tfIdfVectorizer=TfidfVectorizer(decode_error ='ignore',use_idf=True, lowercase=True)\n",
    "  tf_idf = tfIdfVectorizer.fit_transform(liststrings)\n",
    "  dataIdf = pd.DataFrame(tfIdfVectorizer.idf_ , index=tfIdfVectorizer.get_feature_names(), columns=['IDF']).T\n",
    "  dataTf_Idf = pd.DataFrame(tf_idf.todense(), columns=tfIdfVectorizer.get_feature_names())\n",
    "  \n",
    "  \n",
    "  postagensData = pd.DataFrame(liststrings, columns=['Postagens']).dropna()\n",
    "\n",
    "  for col in dataIdf.columns:\n",
    "    if(col != 'Unnamed: 0'):\n",
    "        dataTf_Idf.loc[dataTf_Idf[col] != 0.0, col] = dataIdf.iloc[0][col]\n",
    "\n",
    "  return dataTf_Idf.dropna(), postagensData\n",
    "\n",
    "def ICF():\n",
    "   postagensRotulado = pd.read_csv('postagensRotulado.csv', sep=';', decimal=',') \n",
    "   finalIdfVector = pd.read_csv('idfRotulado.csv', sep=';', decimal=',').drop(['Classification'], axis=1)\n",
    "\n",
    "   postagens2 = postagensRotulado.where(postagensRotulado[\"Classification\"] == 2).dropna().Postagens\n",
    "   postagens1 = postagensRotulado.where(postagensRotulado[\"Classification\"] == 1).dropna().Postagens\n",
    "   postagens0 = postagensRotulado.where(postagensRotulado[\"Classification\"] == 0).dropna().Postagens\n",
    "\n",
    "   achou = False\n",
    "   icfVal = []\n",
    "\n",
    "   for word in finalIdfVector.columns:\n",
    "      qtdWord = 0\n",
    "      for post in postagens2:\n",
    "         if(achou):\n",
    "            break\n",
    "         for word2 in post.split():\n",
    "            if(achou):\n",
    "               break\n",
    "            if(word == word2):\n",
    "               qtdWord += 1\n",
    "               achou = True\n",
    "               break\n",
    "      achou = False\n",
    "      for post in postagens1:\n",
    "         if(achou):\n",
    "            break\n",
    "         for word2 in post.split():\n",
    "            if(achou):\n",
    "               break\n",
    "            if(word == word2):\n",
    "               qtdWord += 1\n",
    "               achou = True\n",
    "               break\n",
    "      achou = False\n",
    "      for post in postagens0:\n",
    "         if(achou):\n",
    "            break\n",
    "         for word2 in post.split():\n",
    "            if(achou):\n",
    "               break\n",
    "            if(word == word2):\n",
    "               qtdWord += 1\n",
    "               achou = True\n",
    "               break\n",
    "      if(qtdWord != 0):\n",
    "         icfVal.append(math.log(1 + 3/qtdWord))\n",
    "      if(qtdWord == 0):\n",
    "         icfVal.append(0)\n",
    "\n",
    "   dataIcf = pd.DataFrame(icfVal , index=finalIdfVector.columns).T   \n",
    "\n",
    "   for col in dataIcf.columns:\n",
    "      if(col != 'Unnamed: 0'):\n",
    "         finalIdfVector.loc[finalIdfVector[col] != 0.0, col] = dataIcf.iloc[0][col] \n",
    "\n",
    "   finalIdfVector['Classification'] =   postagensRotulado.Classification \n",
    "   finalIdfVector.to_csv('ICF.csv', sep=';', decimal=',', float_format='%.3f') \n",
    "\n",
    "def RfIdf():\n",
    "  file = open(str(Path.home()) + \"\\Documents\\Python\\PJ4\\C2\\documentosNoDuplicate.txt\",\"r\", encoding=\"utf8\")\n",
    "  liststrings = file.readlines()\n",
    "  liststrings.remove('Nao lidaBem-vindo ao Facebook! Toque aqui para encontrar pessoas que voce conhece e adiciona-las aos amigos.\\n')\n",
    "  liststrings.remove('\\n')\n",
    "\n",
    "  tfIdfVectorizer=TfidfVectorizer(decode_error ='ignore',use_idf=True, lowercase=True)\n",
    "  tf_idf = tfIdfVectorizer.fit_transform(liststrings)\n",
    "  dataTf_Idf = pd.DataFrame(tf_idf.todense(), columns=tfIdfVectorizer.get_feature_names())\n",
    "  #dataRF = pd.DataFrame({ \"Words\": [], \"RF\": []})\n",
    "  \n",
    "  qtdTotal = 0\n",
    "  x = 0\n",
    "  rfidfVal = []\n",
    "  \n",
    "  for post in liststrings:\n",
    "     qtdTotal += len(post.split())\n",
    "\n",
    "  for word in tfIdfVectorizer.get_feature_names():\n",
    "     qtdWord = 0\n",
    "     for post in liststrings:\n",
    "        for word2 in post.split():\n",
    "          if(word == word2):\n",
    "             qtdWord += 1\n",
    "     rfidfVal.append(qtdWord/qtdTotal * tfIdfVectorizer.idf_[x] )\n",
    "     x += 1\n",
    "     #dataRF = dataRF.append({ \"Words\": word, \"RF\": qtdWord/qtdTotal}, ignore_index=True)\n",
    "  \n",
    "   \n",
    "  dataRfIdf = pd.DataFrame(rfidfVal , index=tfIdfVectorizer.get_feature_names(), columns=['IDF']).T    \n",
    "  \n",
    "  for col in dataRfIdf.columns:\n",
    "    if(col != 'Unnamed: 0'):\n",
    "        dataTf_Idf.loc[dataTf_Idf[col] != 0.0, col] = dataRfIdf.iloc[0][col]\n",
    "\n",
    "  return dataTf_Idf.dropna()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "idfvector, postagensData = idf()\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=0).fit(idfvector)\n",
    "\n",
    "idfvector['Classification'] = kmeans.labels_\n",
    "postagensData['Classification'] = kmeans.labels_\n",
    "\n",
    "def aleatorio(x):\n",
    "  postagemAleatoria = x[x.Classification == 0].sample(n = 5, random_state= 0, replace = True);\n",
    "  postagemAleatoria = postagemAleatoria.append(x[x.Classification == 1].sample(n = 5, random_state= 0, replace = True));\n",
    "  postagemAleatoria = postagemAleatoria.append(x[x.Classification == 2].sample(n = 5, random_state= 0, replace = True));\n",
    "  return postagemAleatoria\n",
    "\n",
    "y = aleatorio(postagensData)\n",
    "\n",
    "finalIdfVector = idfvector[idfvector.Classification == 1]\n",
    "idfvector = idfvector[idfvector.Classification != 1]\n",
    "idfvector = idfvector.drop(columns=['Classification'])\n",
    "\n",
    "finalpostagensData = postagensData[postagensData.Classification == 1]\n",
    "postagensData = postagensData[postagensData.Classification != 1]\n",
    "postagensData = postagensData.drop(columns=['Classification'])\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=0).fit(idfvector)\n",
    "\n",
    "idfvector['Classification'] = kmeans.labels_\n",
    "postagensData['Classification'] = kmeans.labels_\n",
    "\n",
    "y = aleatorio(postagensData)\n",
    "\n",
    "idfvector1 = idfvector[idfvector.Classification == 1].drop(columns=['Classification'])\n",
    "idfvector2 = idfvector[idfvector.Classification == 2].drop(columns=['Classification'])\n",
    "idfvector0 = idfvector[idfvector.Classification == 0].drop(columns=['Classification'])\n",
    "\n",
    "postagensData1 = postagensData[postagensData.Classification == 1].drop(columns=['Classification'])\n",
    "postagensData2 = postagensData[postagensData.Classification == 2].drop(columns=['Classification'])\n",
    "postagensData0 = postagensData[postagensData.Classification == 0].drop(columns=['Classification'])\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=0).fit(idfvector1)\n",
    "\n",
    "idfvector1['Classification'] = kmeans.labels_\n",
    "postagensData1['Classification'] = kmeans.labels_\n",
    "\n",
    "y = aleatorio(postagensData1)\n",
    "\n",
    "lines =  idfvector1[idfvector1.Classification == 0]\n",
    "lines['Classification'] = lines['Classification'].replace(0,1)\n",
    "finalIdfVector = finalIdfVector.append(lines)\n",
    "idfvector1 = idfvector1[idfvector1.Classification != 0]\n",
    "idfvector1 = idfvector1.drop(columns=['Classification'])\n",
    "\n",
    "lines =  postagensData1[postagensData1.Classification == 0]\n",
    "lines['Classification'] = lines['Classification'].replace(0,1)\n",
    "finalpostagensData = finalpostagensData.append(lines)\n",
    "postagensData1 = postagensData1[postagensData1.Classification != 0]\n",
    "postagensData1 = postagensData1.drop(columns=['Classification'])\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=0).fit(idfvector1)\n",
    "\n",
    "idfvector1['Classification'] = kmeans.labels_\n",
    "postagensData1['Classification'] = kmeans.labels_\n",
    "\n",
    "y = aleatorio(postagensData1)\n",
    "\n",
    "finalIdfVector = finalIdfVector.append(idfvector1[idfvector1.Classification == 2])\n",
    "idfvector1 = idfvector1[idfvector1.Classification != 2]\n",
    "idfvector1 = idfvector1.drop(columns=['Classification'])\n",
    "\n",
    "finalpostagensData = finalpostagensData.append(postagensData1[postagensData1.Classification == 2])\n",
    "postagensData1 = postagensData1[postagensData1.Classification != 2]\n",
    "postagensData1 = postagensData1.drop(columns=['Classification'])\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=0).fit(idfvector1)\n",
    "\n",
    "idfvector1['Classification'] = kmeans.labels_\n",
    "postagensData1['Classification'] = kmeans.labels_\n",
    "\n",
    "y = aleatorio(postagensData1)\n",
    "\n",
    "lines =  idfvector1[idfvector1.Classification == 2]\n",
    "lines['Classification'] = lines['Classification'].replace(2,0)\n",
    "finalIdfVector = finalIdfVector.append(lines)\n",
    "\n",
    "lines =  idfvector1[idfvector1.Classification != 2]\n",
    "lines['Classification'] = lines['Classification'].replace(0,1)\n",
    "finalIdfVector = finalIdfVector.append(lines)\n",
    "\n",
    "lines =  postagensData1[postagensData1.Classification == 2]\n",
    "lines['Classification'] = lines['Classification'].replace(2,0)\n",
    "finalpostagensData = finalpostagensData.append(lines)\n",
    "\n",
    "lines =  postagensData1[postagensData1.Classification != 2]\n",
    "lines['Classification'] = lines['Classification'].replace(0,1)\n",
    "finalpostagensData = finalpostagensData.append(lines)\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=0).fit(idfvector2)\n",
    "\n",
    "idfvector2['Classification'] = kmeans.labels_\n",
    "postagensData2['Classification'] = kmeans.labels_\n",
    "\n",
    "y = aleatorio(postagensData2)\n",
    "\n",
    "lines =  idfvector2[idfvector2.Classification != 2]\n",
    "lines['Classification'] = lines['Classification'].replace(0,1)\n",
    "finalIdfVector = finalIdfVector.append(lines)\n",
    "idfvector2 = idfvector2[idfvector2.Classification == 2]\n",
    "idfvector2 = idfvector2.drop(columns=['Classification'])\n",
    "\n",
    "lines =  postagensData2[postagensData2.Classification != 2]\n",
    "lines['Classification'] = lines['Classification'].replace(0,1)\n",
    "finalpostagensData = finalpostagensData.append(lines)\n",
    "postagensData2 = postagensData2[postagensData2.Classification == 2]\n",
    "postagensData2 = postagensData2.drop(columns=['Classification'])\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=0).fit(idfvector2)\n",
    "\n",
    "idfvector2['Classification'] = kmeans.labels_\n",
    "postagensData2['Classification'] = kmeans.labels_\n",
    "\n",
    "y = aleatorio(postagensData2)\n",
    "\n",
    "finalIdfVector = finalIdfVector.append(idfvector2[idfvector2.Classification == 1])\n",
    "idfvector2 = idfvector2[idfvector2.Classification != 1]\n",
    "idfvector2 = idfvector2.drop(columns=['Classification'])\n",
    "\n",
    "finalpostagensData = finalpostagensData.append(postagensData2[postagensData2.Classification == 1])\n",
    "postagensData2 = postagensData2[postagensData2.Classification != 1]\n",
    "postagensData2 = postagensData2.drop(columns=['Classification'])\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=0).fit(idfvector2)\n",
    "\n",
    "idfvector2['Classification'] = kmeans.labels_\n",
    "postagensData2['Classification'] = kmeans.labels_\n",
    "\n",
    "y = aleatorio(postagensData2)\n",
    "\n",
    "lines =  idfvector2[idfvector2.Classification == 2]\n",
    "lines['Classification'] = lines['Classification'].replace(2,0)\n",
    "finalIdfVector = finalIdfVector.append(lines)\n",
    "\n",
    "lines =  idfvector2[idfvector2.Classification != 2]\n",
    "lines['Classification'] = lines['Classification'].replace(0,1)\n",
    "finalIdfVector = finalIdfVector.append(lines)\n",
    "\n",
    "lines =  postagensData2[postagensData2.Classification == 2]\n",
    "lines['Classification'] = lines['Classification'].replace(2,0)\n",
    "finalpostagensData = finalpostagensData.append(lines)\n",
    "\n",
    "lines =  postagensData2[postagensData2.Classification != 2]\n",
    "lines['Classification'] = lines['Classification'].replace(0,1)\n",
    "finalpostagensData = finalpostagensData.append(lines)\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=0).fit(idfvector0)\n",
    "\n",
    "idfvector0['Classification'] = kmeans.labels_\n",
    "postagensData0['Classification'] = kmeans.labels_\n",
    "\n",
    "y = aleatorio(postagensData0)\n",
    "\n",
    "finalIdfVector = finalIdfVector.append(idfvector0)\n",
    "\n",
    "finalpostagensData = finalpostagensData.append(postagensData0)\n",
    "\n",
    "finalIdfVector.to_csv('idfRotulado.csv', sep=';', decimal=',', float_format='%.3f') \n",
    "finalpostagensData.to_csv('postagensRotulado.csv', sep=';', decimal=',', float_format='%.3f') \n",
    "ICF()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def RfIdf():\n",
    "  file = open(str(Path.home()) + \"\\Documents\\Python\\PJ4\\C2\\documentosNoDuplicate.txt\",\"r\", encoding=\"utf8\")\n",
    "  liststrings = file.readlines()\n",
    "  liststrings.remove('Nao lidaBem-vindo ao Facebook! Toque aqui para encontrar pessoas que voce conhece e adiciona-las aos amigos.\\n')\n",
    "  liststrings.remove('\\n')\n",
    "\n",
    "  postagensRotulado = pd.read_csv('postagensRotulado.csv', sep=';', decimal=',', float_format='%.3f') \n",
    "\n",
    "  tfIdfVectorizer=TfidfVectorizer(decode_error ='ignore',use_idf=True, lowercase=True)\n",
    "  tf_idf = tfIdfVectorizer.fit_transform(liststrings)\n",
    "  dataTf_Idf = pd.DataFrame(tf_idf.todense(), columns=tfIdfVectorizer.get_feature_names())\n",
    "  #dataRF = pd.DataFrame({ \"Words\": [], \"RF\": []})\n",
    "  \n",
    "  qtdTotal = 0\n",
    "  x = 0\n",
    "  rfidfVal = []\n",
    "  \n",
    "  for post in liststrings:\n",
    "     qtdTotal += len(post.split())\n",
    "\n",
    "  for word in tfIdfVectorizer.get_feature_names():\n",
    "     qtdWord = 0\n",
    "     for post in liststrings:\n",
    "        for word2 in post.split():\n",
    "          if(word == word2):\n",
    "             qtdWord += 1\n",
    "     rfidfVal.append(qtdWord/qtdTotal * tfIdfVectorizer.idf_[x] )\n",
    "     x += 1\n",
    "     #dataRF = dataRF.append({ \"Words\": word, \"RF\": qtdWord/qtdTotal}, ignore_index=True)\n",
    "  \n",
    "   \n",
    "  dataRfIdf = pd.DataFrame(rfidfVal , index=tfIdfVectorizer.get_feature_names(), columns=['IDF']).T    \n",
    "  \n",
    "  for col in dataRfIdf.columns:\n",
    "    if(col != 'Unnamed: 0'):\n",
    "        dataTf_Idf.loc[dataTf_Idf[col] != 0.0, col] = dataRfIdf.iloc[0][col]\n",
    "\n",
    "  return dataTf_Idf.dropna()\n",
    "  \n",
    "\n",
    "def ICF():\n",
    "   postagensRotulado = pd.read_csv('postagensRotulado.csv', sep=';', decimal=',') \n",
    "   finalIdfVector = pd.read_csv('idfRotulado.csv', sep=';', decimal=',').drop(['Classification'], axis=1)\n",
    "\n",
    "   postagens2 = postagensRotulado.where(postagensRotulado[\"Classification\"] == 2).dropna().Postagens\n",
    "   postagens1 = postagensRotulado.where(postagensRotulado[\"Classification\"] == 1).dropna().Postagens\n",
    "   postagens0 = postagensRotulado.where(postagensRotulado[\"Classification\"] == 0).dropna().Postagens\n",
    "\n",
    "   achou = False\n",
    "   icfVal = []\n",
    "\n",
    "   for word in finalIdfVector.columns:\n",
    "      qtdWord = 0\n",
    "      for post in postagens2:\n",
    "         if(achou):\n",
    "            break\n",
    "         for word2 in post.split():\n",
    "            if(achou):\n",
    "               break\n",
    "            if(word == word2):\n",
    "               qtdWord += 1\n",
    "               achou = True\n",
    "               break\n",
    "      achou = False\n",
    "      for post in postagens1:\n",
    "         if(achou):\n",
    "            break\n",
    "         for word2 in post.split():\n",
    "            if(achou):\n",
    "               break\n",
    "            if(word == word2):\n",
    "               qtdWord += 1\n",
    "               achou = True\n",
    "               break\n",
    "      achou = False\n",
    "      for post in postagens0:\n",
    "         if(achou):\n",
    "            break\n",
    "         for word2 in post.split():\n",
    "            if(achou):\n",
    "               break\n",
    "            if(word == word2):\n",
    "               qtdWord += 1\n",
    "               achou = True\n",
    "               break\n",
    "      if(qtdWord != 0):\n",
    "         icfVal.append(math.log(1 + 3/qtdWord))\n",
    "      if(qtdWord == 0):\n",
    "         icfVal.append(0)\n",
    "\n",
    "   dataIcf = pd.DataFrame(icfVal , index=finalIdfVector.columns).T   \n",
    "\n",
    "   for col in dataIcf.columns:\n",
    "      if(col != 'Unnamed: 0'):\n",
    "         finalIdfVector.loc[finalIdfVector[col] != 0.0, col] = dataIcf.iloc[0][col] \n",
    "\n",
    "   finalIdfVector['Classification'] =   postagensRotulado.Classification \n",
    "   finalIdfVector.to_csv('ICF.csv', sep=';', decimal=',', float_format='%.3f') \n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def ICF():\n",
    "  file = open(str(Path.home()) + \"\\Documents\\Python\\PJ4\\C2\\documentosNoDuplicate.txt\",\"r\", encoding=\"utf8\")\n",
    "  liststrings = file.readlines()\n",
    "  liststrings.remove('Nao lidaBem-vindo ao Facebook! Toque aqui para encontrar pessoas que voce conhece e adiciona-las aos amigos.\\n')\n",
    "  liststrings.remove('\\n')\n",
    "\n",
    "  tfIdfVectorizer=TfidfVectorizer(decode_error ='ignore',use_idf=True, lowercase=True)\n",
    "  tf_idf = tfIdfVectorizer.fit_transform(liststrings)\n",
    "  dataTf_Idf = pd.DataFrame(tf_idf.todense(), columns=tfIdfVectorizer.get_feature_names())\n",
    "  \n",
    "  x = 0\n",
    "  icfVal = []\n",
    "  \n",
    "  for post in liststrings:\n",
    "     qtdTotal += len(post.split())\n",
    "\n",
    "  for word in tfIdfVectorizer.get_feature_names():\n",
    "     qtdWord = 0\n",
    "     for post in liststrings:\n",
    "        for word2 in post.split():\n",
    "          if(word == word2):\n",
    "             qtdWord += 1\n",
    "     rfidfVal.append(qtdWord/qtdTotal * tfIdfVectorizer.idf_[x] )\n",
    "     x += 1\n",
    "     #dataRF = dataRF.append({ \"Words\": word, \"RF\": qtdWord/qtdTotal}, ignore_index=True)\n",
    "  \n",
    "   \n",
    "  dataRfIdf = pd.DataFrame(rfidfVal , index=tfIdfVectorizer.get_feature_names(), columns=['IDF']).T    \n",
    "  \n",
    "  for col in dataRfIdf.columns:\n",
    "    if(col != 'Unnamed: 0'):\n",
    "        dataTf_Idf.loc[dataTf_Idf[col] != 0.0, col] = dataRfIdf.iloc[0][col]\n",
    "\n",
    "  return dataTf_Idf.dropna()\n",
    "  \n",
    "\n",
    "teste = RfIdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d7bdcd9f84821488ca1aefdd5b383dc6099ae3b1ac329612af81525cc197a794"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
